{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# **Documento Técnico: Algoritmo de Roteamento Semântico com Base em Similaridade de Vetores**\n",
    "\n",
    "## **Visão Geral**\n",
    "\n",
    "Este documento descreve o processo de implementação de um \"Roteador Semântico\", um algoritmo que usa embeddings (representações vetoriais) para rotear uma solicitação para o serviço ou endpoint mais apropriado, com base na similaridade semântica da consulta de entrada.\n",
    "\n",
    "### **Descrição do Algoritmo**\n",
    "\n",
    "O algoritmo segue os seguintes passos:\n",
    "\n",
    "1. **Gerar Embedding da Consulta**: A consulta é convertida em um embedding (representação vetorial) usando um modelo de embeddings.\n",
    "2. **Buscar Similaridades**: O embedding da consulta é comparado com um conjunto de embeddings pré-existentes no banco de dados para encontrar as correspondências mais próximas.\n",
    "3. **Agrupar por Rota**: As correspondências mais próximas são agrupadas pelas rotas ou serviços a que pertencem.\n",
    "4. **Filtrar Pontuações**: O algoritmo filtra as rotas que não atendem a um determinado limite, com base na soma de suas pontuações de similaridade.\n",
    "5. **Selecionar a Melhor Rota**: Por fim, a rota com a maior pontuação de similaridade é escolhida para lidar com a consulta.\n",
    "\n",
    "\n"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> Modulos Nativos ou instalados",
   "id": "dab077ce2f10b8f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import uuid\n",
    "from typing import Dict, List, Literal\n",
    "\n",
    "\n",
    "from sqlmodel import Session, select"
   ],
   "id": "42793da5e7fa64ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> User Modules",
   "id": "85d848ce9ce7b5f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from database import pg_engine # SQLAlchemy engine\n",
    "from models import Embedding, Collection # SQLModel models\n",
    "from utils import embed # Embedding function"
   ],
   "id": "69168c129ef174ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _set_collection_id(session: Session, layer: Literal['entry_layer', 'customer_layer']) -> uuid.UUID:\n",
    "    # Busca os IDs das coleções com base na camada\n",
    "    collections = session.exec(\n",
    "        select(Collection)\n",
    "    ).all()\n",
    "    \n",
    "    collection_ids = {collection.name: collection.uuid for collection in collections}\n",
    "\n",
    "    if layer == 'entry_layer':\n",
    "        return collection_ids['routes']\n",
    "    elif layer == 'customer_layer':\n",
    "        return collection_ids['customer_routes']"
   ],
   "id": "62727a10a3622e58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Passos do Algoritmo**\n",
    "\n",
    "#### 1. **Gerar Embedding da Consulta**"
   ],
   "id": "73536d7d755158bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = \"create a new customer in ge3\"\n",
    "layer = \"entry_layer\"\n",
    "threshold = 0.5\n",
    "\n",
    "vector = embed(query)"
   ],
   "id": "4b344260195dadfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- A consulta, \"create a new customer in ge3\", é convertida em uma representação vetorial usando um modelo de embeddings (por exemplo, GPT-3 da OpenAI ou modelos semelhantes).\n",
    "- A variável `threshold` representa a pontuação mínima de similaridade exigida para que uma rota seja considerada.\n",
    "\n",
    "#### 2. **Busca de Similaridade**\n",
    "- Os embeddings dos documentos ou serviços predefinidos estão armazenados no modelo `Embedding`."
   ],
   "id": "4e7a6a68cd61ec5d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with Session(pg_engine) as session:\n",
    "    collection_id = _set_collection_id(session, layer)\n",
    "\n",
    "    distance_score = Embedding.embedding.max_inner_product(vector).label('distance_score')\n",
    "\n",
    "    routes = session.exec(\n",
    "        select(-distance_score, Embedding.document, Embedding.cmetadata)\n",
    "        .where(collection_id == Embedding.collection_id)\n",
    "        .order_by(distance_score)\n",
    "        .limit(25)\n",
    "    ).all()"
   ],
   "id": "88abff2f77eb15e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- O embedding da consulta é comparado com esses embeddings armazenados usando um produto interno (produto escalar) para encontrar as 25 rotas (documentos) mais semelhantes no banco de dados.\n",
    "- No cálculo de similaridade, usamos o produto interno multiplicado por -1, pois o Postgres suporta apenas varreduras de índice de ordem ASC em operadores, assim o valor vem negativo da consulta SQL.\n"
   ],
   "id": "859485f8fa674965"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with Session(pg_engine) as session:\n",
    "    collection_id = _set_collection_id(session, layer)\n",
    "\n",
    "    distance_score = Embedding.embedding.max_inner_product(vector).label('distance_score')\n",
    "    \n",
    "    routes = session.exec(\n",
    "        select((1 - distance_score / 2), Embedding.document, Embedding.cmetadata)  # Ajuste com cosseno\n",
    "        .where(collection_id == Embedding.collection_id)\n",
    "        .order_by(distance_score)\n",
    "        .limit(25)\n",
    "    ).all()"
   ],
   "id": "4759731bfa1f54e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- No cálculo de similaridade por cosseno, ajustamos para 1 - (distance_score / 2) para garantir que os valores resultantes estejam entre 0 e 1.\n",
    "- onde 0 significa \"completamente diferente\" e 1 significa \"idêntico\"."
   ],
   "id": "a77947aca47f9758"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. **Agrupamento por Rota**",
   "id": "4c9d4227a6c9577e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "grouped_data: Dict[str, List[float]] = {}\n",
    "for score, document, metadata in routes:\n",
    "    route_name = metadata['route_name']\n",
    "    if route_name not in grouped_data:\n",
    "        grouped_data[route_name] = []\n",
    "    grouped_data[route_name].append(score)"
   ],
   "id": "5efabcb462ef7b9a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- As pontuações de similaridade são agrupadas pelo nome da rota ou serviço ao qual pertencem, criando um dicionário onde a chave é o nome da rota e o valor é uma lista de pontuações de similaridade.\n",
    "\n",
    "#### 4. **Filtragem por Limite**\n"
   ],
   "id": "9bc03e3659f86cd0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "filtered_routes = {route_name: scores for route_name, scores in grouped_data.items() if sum(scores) >= threshold}",
   "id": "9614cbaa033ef6af"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- As rotas são filtradas com base em um limite de pontuação. Somente as rotas com uma pontuação total de similaridade maior ou igual ao limite são mantidas.\n",
    "\n",
    "#### 5. **Seleção da Melhor Rota**\n"
   ],
   "id": "9adedb10ee0f453"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "sum_scores = {route_name: sum(scores) for route_name, scores in filtered_routes.items()}",
   "id": "bc8a7bedeaea2f3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```shell\n",
    "{'customers': 15.390514, 'automations': 7.2249}\n",
    "```"
   ],
   "id": "b7c2b809e87b0b4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sorted_routes = dict(sorted(sum_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "best_route = max(sorted_routes, key=sorted_routes.get)"
   ],
   "id": "ad4e5eacc05f8c86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```shell\n",
    "'customer'\n",
    "```\n",
    "- As rotas são classificadas pela pontuação total de similaridade em ordem decrescente, e a rota com a maior pontuação é selecionada como a melhor rota para a consulta.\n",
    "\n",
    "---\n",
    "\n",
    "## **Implementação em C#**\n",
    "\n",
    "Esta seção fornece orientações para a implementação do algoritmo em C#. Os passos principais incluem a geração de embeddings, a consulta ao banco de dados para recuperar embeddings e a filtragem das rotas com base nas pontuações de similaridade.\n",
    "\n",
    "### **Pré-requisitos**\n",
    "- **Geração de Embeddings**: Utilize um modelo ou biblioteca de NLP existente, como HuggingFace Transformers ou OpenAI, para gerar embeddings vetoriais para consultas no seu aplicativo C#. Você pode usar uma API ou um modelo, como o GPT-3, para converter consultas em vetores.\n",
    "- **Configuração do Banco de Dados**: Armazene os embeddings de cada documento/rota em um banco de dados. Você pode usar PostgreSQL ou qualquer outro banco relacional, juntamente com um ORM em C#, como o Entity Framework.\n",
    "\n",
    "### **Componentes Principais**\n",
    "\n",
    "#### 1. **Gerar Embedding da Consulta**\n",
    "\n",
    "```csharp\n",
    "// Supondo que você tenha um serviço que gera embeddings para textos\n",
    "var embeddingService = new EmbeddingService();\n",
    "string query = \"create a new customer in ge3\";\n",
    "float[] queryVector = embeddingService.Embed(query);\n",
    "```\n",
    "\n",
    "#### 2. **Buscar Pontuações de Similaridade**\n",
    "\n",
    "```csharp\n",
    "using (var context = new EmbeddingContext())\n",
    "{\n",
    "    var collectionId = SetCollectionId(\"entry_layer\");\n",
    "\n",
    "    // Obter as 25 rotas mais semelhantes com base no produto interno\n",
    "    var routes = context.Embeddings\n",
    "        .Where(e => e.CollectionId == collectionId)\n",
    "        .Select(e => new {\n",
    "            DistanceScore = MaxInnerProduct(queryVector, e.Vector),\n",
    "            RouteName = e.RouteName,\n",
    "            Metadata = e.Metadata\n",
    "        })\n",
    "        .OrderByDescending(e => e.DistanceScore)\n",
    "        .Take(25)\n",
    "        .ToList();\n",
    "}\n",
    "```\n",
    "- Você precisará implementar a função de similaridade ou [#entity-framework-core](https://github.com/pgvector/pgvector-dotnet?tab=readme-ov-file#entity-framework-core)\n",
    "\n",
    "#### 3. **Agrupar por Rota**\n",
    "\n",
    "```csharp\n",
    "var groupedData = new Dictionary<string, List<float>>();\n",
    "\n",
    "foreach (var route in routes)\n",
    "{\n",
    "    if (!groupedData.ContainsKey(route.RouteName))\n",
    "    {\n",
    "        groupedData[route.RouteName] = new List<float>();\n",
    "    }\n",
    "    groupedData[route.RouteName].Add(route.DistanceScore);\n",
    "}\n",
    "```\n",
    "\n",
    "#### 4. **Filtrar por Limite**\n",
    "\n",
    "```csharp\n",
    "var threshold = 0.5;\n",
    "var filteredRoutes = groupedData\n",
    "    .Where(g => g.Value.Sum() >= threshold)\n",
    "    .ToDictionary(g => g.Key, g => g.Value);\n",
    "```\n",
    "\n",
    "#### 5. **Selecionar a Melhor Rota**\n",
    "\n",
    "```csharp\n",
    "var bestRoute = filteredRoutes\n",
    "    .OrderByDescending(g => g.Value.Sum())\n",
    "    .FirstOrDefault().Key;\n",
    "\n",
    "Console.WriteLine($\"A melhor rota para a consulta é: {bestRoute}\");\n",
    "```\n",
    "\n",
    "### **Design de Banco de Dados para Embeddings**\n",
    "- **Tabela de Embeddings**:\n",
    "    - `Id`: Chave primária\n",
    "    - `RouteName`: Nome da rota (ex: \"customers\", \"automations\")\n",
    "    - `Vector`: O vetor do embedding, armazenado como `float[]` ou string serializada.\n",
    "    - `Metadata`: Metadados adicionais relacionados à rota\n",
    "    - `CollectionId`: Identifica a camada ou coleção a que o embedding pertence (ex: \"entry_layer\")\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusão**\n",
    "\n",
    "Este documento descreve o processo de construção de um roteador semântico tanto em Python (implementação original) quanto como seria idealmente em C#. Os principais passos envolvem a geração de embeddings para a consulta, o cálculo de pontuações de similaridade com embeddings armazenados, o agrupamento dos resultados por rota e a seleção da rota mais relevante com base nas pontuações.\n",
    "\n",
    "Seguindo as orientações acima, um desenvolvedor pode implementar um algoritmo de roteamento escalável e eficiente com base em similaridade vetorial em um ambiente C#.\n",
    "\n",
    "--- \n"
   ],
   "id": "ff237ce0fafb6139"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "28526e4d7239b2df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
